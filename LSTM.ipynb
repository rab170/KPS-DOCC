{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "from keras.datasets import reuters\n",
    "from nltk.corpus import reuters as NLTK_reuters\n",
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 200\n",
    "\n",
    "def load_reuters_nltk():\n",
    "    data = {'train':[], 'test':[]}\n",
    "\n",
    "    vals = {doc:(NLTK_reuters.words(doc), NLTK_reuters.categories(doc)) for doc in NLTK_reuters.fileids()}\n",
    "    for key, val in vals.items():\n",
    "        text = val[0][0:sequence_length]\n",
    "        cats = val[1]\n",
    "        for cat in cats:\n",
    "            p = (text, cat)\n",
    "            if 'train' in key: data['train'].append(p)\n",
    "            if 'test' in key: data['test'].append(p) \n",
    "\n",
    "    (x_test, y_test) = zip(*data['test'])\n",
    "    (x_train, y_train) = zip(*data['train'])\n",
    "    return (x_train, y_train), (x_test, y_test)\n",
    "\n",
    "def load_reuters_keras():\n",
    "    return reuters.load_data(path=\"reuters.npz\", num_words=None, skip_top=0, maxlen=sequence_length, \n",
    "                             test_split=0.2, seed=113, start_char=1, oov_char=2, index_from=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) =  load_reuters_keras()\n",
    "y_train = keras.utils.to_categorical(y_train)\n",
    "y_test = keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_classes = y_test.shape[1]\n",
    "embedding_vecor_length = 32\n",
    "batch_size = 64\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = sequence.pad_sequences(x_train, maxlen=sequence_length)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 200, 200)          6195400   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 46)                9246      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 46)                0         \n",
      "=================================================================\n",
      "Total params: 6,525,446\n",
      "Trainable params: 6,525,446\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "hidden_neurons = 200 \n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(np.max(x_train) + 1, hidden_neurons, input_length=sequence_length))\n",
    "model.add(LSTM(hidden_neurons,  dropout=0.2, recurrent_dropout=0.2, return_sequences=False))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('relu'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7076 samples, validate on 1770 samples\n",
      "Epoch 1/5\n",
      "7076/7076 [==============================] - 80s 11ms/step - loss: 3.5910 - acc: 0.4870 - val_loss: 3.1954 - val_acc: 0.5644\n",
      "Epoch 2/5\n",
      "7076/7076 [==============================] - 79s 11ms/step - loss: 2.9071 - acc: 0.5855 - val_loss: 3.0643 - val_acc: 0.6282\n",
      "Epoch 3/5\n",
      "7076/7076 [==============================] - 79s 11ms/step - loss: 2.7810 - acc: 0.5599 - val_loss: 3.0912 - val_acc: 0.5955\n",
      "Epoch 4/5\n",
      "7076/7076 [==============================] - 79s 11ms/step - loss: 2.4962 - acc: 0.5681 - val_loss: 3.4558 - val_acc: 0.5407\n",
      "Epoch 5/5\n",
      "7076/7076 [==============================] - 79s 11ms/step - loss: 2.2469 - acc: 0.6302 - val_loss: 3.1031 - val_acc: 0.6119\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7f2773b090>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
